<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Web Scraping in Python - Scraping Dwarf Fortress Creatures | Mauício's Log Book</title><meta name=keywords content="Algorithms,String,radix sort"><meta name=description content="Dwarf Fortress I&rsquo;ve lately been caught up in playing Dwarf Fortress with my brother. The game is a single-player simulation where you control a dwarven outpost in a randomly generated world 1.
It&rsquo;s a rough game, really challenging. Nonetheless, fun. The way we would play it is one of us would open the Dwarf Fortress Wiki 2 and feed the other, who&rsquo;s actually controlling the game, informations about it&rsquo;s world."><meta name=author content="Maurício Gomes"><link rel=canonical href=https://maugomes.netlify.app/posts/2020-08-14-scrapy-dwarf-fortress/><link href=/assets/css/stylesheet.min.d85457619e67d31b97f40ed67c71b5efe0b52508ba759e5a9da0760afd6707db.css integrity="sha256-2FRXYZ5n0xuX9A7WfHG17+C1JQi6dZ5anaB2Cv1nB9s=" rel="preload stylesheet" as=style><link rel=icon href=https://maugomes.netlify.app/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://maugomes.netlify.app/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://maugomes.netlify.app/favicon-32x32.png><link rel=apple-touch-icon href=https://maugomes.netlify.app/apple-touch-icon.png><link rel=mask-icon href=https://maugomes.netlify.app/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.82.0"><link rel=alternate hreflang=en href=https://maugomes.netlify.app/posts/2020-08-14-scrapy-dwarf-fortress/><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-176567472-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Web Scraping in Python - Scraping Dwarf Fortress Creatures"><meta property="og:description" content="Dwarf Fortress I&rsquo;ve lately been caught up in playing Dwarf Fortress with my brother. The game is a single-player simulation where you control a dwarven outpost in a randomly generated world 1.
It&rsquo;s a rough game, really challenging. Nonetheless, fun. The way we would play it is one of us would open the Dwarf Fortress Wiki 2 and feed the other, who&rsquo;s actually controlling the game, informations about it&rsquo;s world."><meta property="og:type" content="article"><meta property="og:url" content="https://maugomes.netlify.app/posts/2020-08-14-scrapy-dwarf-fortress/"><meta property="og:image" content="https://maugomes.netlify.app/img/mauri.jpeg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-08-14T09:00:00+00:00"><meta property="article:modified_time" content="2020-08-14T09:00:00+00:00"><meta property="og:site_name" content="Mauício's Log Book"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://maugomes.netlify.app/img/mauri.jpeg"><meta name=twitter:title content="Web Scraping in Python - Scraping Dwarf Fortress Creatures"><meta name=twitter:description content="Dwarf Fortress I&rsquo;ve lately been caught up in playing Dwarf Fortress with my brother. The game is a single-player simulation where you control a dwarven outpost in a randomly generated world 1.
It&rsquo;s a rough game, really challenging. Nonetheless, fun. The way we would play it is one of us would open the Dwarf Fortress Wiki 2 and feed the other, who&rsquo;s actually controlling the game, informations about it&rsquo;s world."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://maugomes.netlify.app/posts/"},{"@type":"ListItem","position":2,"name":"Web Scraping in Python - Scraping Dwarf Fortress Creatures","item":"https://maugomes.netlify.app/posts/2020-08-14-scrapy-dwarf-fortress/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Web Scraping in Python - Scraping Dwarf Fortress Creatures","name":"Web Scraping in Python - Scraping Dwarf Fortress Creatures","description":"Dwarf Fortress I\u0026rsquo;ve lately been caught up in playing Dwarf Fortress with my brother. The game is a single-player simulation where you control a dwarven outpost in a randomly generated world 1.\nIt\u0026rsquo;s a rough game, really challenging. Nonetheless, fun. The way we would play it is one of us would open the Dwarf Fortress Wiki 2 and feed the other, who\u0026rsquo;s actually controlling the game, informations about it\u0026rsquo;s world.","keywords":["Algorithms","String","radix sort"],"articleBody":"Dwarf Fortress I’ve lately been caught up in playing Dwarf Fortress with my brother. The game is a single-player simulation where you control a dwarven outpost in a randomly generated world 1.\nIt’s a rough game, really challenging. Nonetheless, fun. The way we would play it is one of us would open the Dwarf Fortress Wiki 2 and feed the other, who’s actually controlling the game, informations about it’s world.\nThe Wiki is pretty useful when you are trying to find out on the run whether that Chinchilla Man you just saw is hostile or not. But what if you don’t want to open a browser every time you want to find it out? Or if you want to use that information locally for something?\nWith the game nowadays having up to 700 different creatures, you surely won’t mannualy gather that information for yourself.\nWeb Scraping and Web Crawling Well you can create a program to extract the data you want from the website in an automated fashion. We call this Web Scraping. Now, Web Scraping often goes hand in hand with Web Crawling, and that’s when you, from a base page, start to follow links and also visit other pages. Web crawlers are also widely reffered to as bots or spiders.\nScraping Creatures If you head to the Creature page of the Dwarf Fortress Wiki, you’ll see tables containing informations about each creature of the game. There’s a name and hostile fields. That’s the information we are looking for.\n\r\rScrapy Scrapy is an open source framework for Web Scraping and Web Crawling in Python3. Using Scrapy makes it easy to request and parse HTML, as it handles a lot of it for us. It’s simple to set it up and get it running. Let’s dive right in to it!\nTo install it, simply open a terminal and\npip install scrapy\rThe first thing to do when working with Scrapy is to set up the framework for our spiders, which can be done through the command scrapy startproject followed by the project name. I will call my project ‘dwarf_fortress’ so,\nscrapy startproject dwarf_fortress\rScrapy will create generic folders, code and config for our crawlers. The structure will be something like:\n\r────dwarf_fortress\r│ scrapy.cfg\r│\r└───dwarf_fortress\r│ items.py\r│ middlewares.py\r│ pipelines.py\r│ settings.py\r│ __init__.py\r│\r├───spiders\r│ │ __init__.py\r│ │\r│ └───__pycache__\r└───__pycache__\rNow that we’ve created a project, let’s go into the directory ‘dwarf_fortress’ and run another command to make Scrapy set up a generic spider for us. That’s a good starting point.\nI’ll name it ‘Creatures’ and say that the base url is ‘dwarffortresswiki.org/index.php/DF2014:Creature’.\ncd dwarf_fortress\rscrapy genspider Creatures dwarffortresswiki.org/index.php/DF2014:Creature\rYou should be able to see the created spider as a new file in the ‘spiders’ folder called Creatures.py.\n# Creatures.py # -*- coding: utf-8 -*- import scrapy class CreaturesSpider(scrapy.Spider): name = 'Creatures' allowed_domains = ['dwarffortresswiki.org/index.php/DF2014:Creature'] start_urls = ['http://dwarffortresswiki.org/index.php/DF2014:Creature/'] def parse(self, response): pass The class CreaturesSpider represents the spider that will grab each creature name hostile information from the Wiki. AllowedDomains restrict the domain of sites the spider can visit.\nNotice that the start url has ‘http’ protocol, while the Wiki uses ‘https’. That alone will make our spider crash, so be sure to fix it.\nOur spider will request the start_url and pass the HTTP response to the parse method. And that’s where we’ll code to fetch the data we need.\nBut first we need to define the structure of the information we are collecting. We can do it in the items.py file. There, we define Classes that represent the information as ‘scrapy.Items’ which are the containers for the data scrapped. Let’s add a name and hostile field.\n# -*- coding: utf-8 -*- # Define here the models for your scraped items import scrapy class DwarfFortressItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() name = scrapy.Field() hostile = scrapy.Field() Now, the last thing we need to do before running the crawler, is to tell our spider where are the name and hostile fields in the HTTP response.\nXpath We can use Xpath syntax in Scrapy to grab only the elements we need from the page.\nBy opening the Wiki ‘Creature page’ in a web browser, we can right click one creature’s Hostile field and go to Inspect Element.\n\r\r\r\rNow, we have to write the path to each field. We start from the outside to the inside, so we first grab every row of every table that has a class ‘wikitable sortable jquery-tablesorter’. In Xpath,\nrow - //table[@class='wikitable sortable jquery-tablesorter']/tbody/tr\nNow, for every row, we take the text of the second element (notice that the text for the ‘name’ element is located at ‘td/a’) and the text of the fourth element.\nname (inside row)- ./td[2]/a/text()\nhostile (inside row) - ./td[4]/text()\nPutting it all together Heading back to the parse method, we import our DwarfFortressItem and write the logic to fetch name and hostile from the response.\n# -*- coding: utf-8 -*- import scrapy from dwarf_fortress.items import DwarfFortressItem class CreaturesSpider(scrapy.Spider): name = 'Creatures' allowed_domains = ['dwarffortresswiki.org/index.php'] start_urls = ['https://dwarffortresswiki.org/index.php/DF2014:Creature'] def parse(self, response): table_rows = response.xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr\") for row in table_rows: name = row.xpath(\"./td[2]/a/text()\").get() hostile = row.xpath(\"./td[4]/text()\").get() if name and hostile: creature = DwarfFortressItem(name=name, hostile=hostile.strip('\\n')) yield creature If name and hostile are not null (that avoids returning other page elements that may happen to match the Xpath), we yield our DwarfFortressItem defined previously.\nTo run our crawler and save the output to a json file,\nscrapy crawl Creatures -o output.json \nAnd that’s it! Looking at the output’s first elements, we’ve successfully scraped the Dwarf Fortress Wiki for Creature name and Hostile information!\n[ {\"name\": \"Dwarf\", \"hostile\": \"No\"}, {\"name\": \"Elf\", \"hostile\": \"Variable\"}, {\"name\": \"Goblin\", \"hostile\": \"Usually\"}, {\"name\": \"Human\", \"hostile\": \"Variable\"}, {\"name\": \"Kobold\", \"hostile\": \"Usually\"}, {\"name\": \"Amphibian man\", \"hostile\": \"Variable\"}, {\"name\": \"Antman\", \"hostile\": \"Variable\"},   http://www.bay12games.com/dwarves/ ↩︎\n https://dwarffortresswiki.org/ ↩︎\n https://scrapy.org/ ↩︎\n   ","wordCount":"977","inLanguage":"en","image":"https://maugomes.netlify.app/img/mauri.jpeg","datePublished":"2020-08-14T09:00:00Z","dateModified":"2020-08-14T09:00:00Z","author":{"@type":"Person","name":"Maurício Gomes"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://maugomes.netlify.app/posts/2020-08-14-scrapy-dwarf-fortress/"},"publisher":{"@type":"Organization","name":"Mauício's Log Book","logo":{"@type":"ImageObject","url":"https://maugomes.netlify.app/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://maugomes.netlify.app/ accesskey=h title="Mauício's Log Book (Alt + H)">Mauício's Log Book</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://maugomes.netlify.app/pt/ title=Português aria-label=Português>Pt</a></li></ul></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://maugomes.netlify.app/posts title=Posts><span>Posts</span></a></li><li><a href=https://maugomes.netlify.app/readinglist title="Reading List"><span>Reading List</span></a></li><li><a href=https://maugomes.netlify.app/about title="About me"><span>About me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Web Scraping in Python - Scraping Dwarf Fortress Creatures</h1><div class=post-meta>August 14, 2020&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Maurício Gomes</div></header><figure class=entry-cover><img loading=lazy src=https://maugomes.netlify.app/img/mauri.jpeg alt><p></p></figure><div class=post-content><h2 id=dwarf-fortress>Dwarf Fortress<a hidden class=anchor aria-hidden=true href=#dwarf-fortress>#</a></h2><p>I&rsquo;ve lately been caught up in playing <strong>Dwarf Fortress</strong> with my brother. The game is a single-player simulation where you control a dwarven outpost in a randomly generated world <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>It&rsquo;s a rough game, really challenging. Nonetheless, <a href=https://dwarffortresswiki.org/index.php/Fun>fun</a>. The way we would play it is one of us would open the Dwarf Fortress Wiki <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> and feed the other, who&rsquo;s actually controlling the game, informations about it&rsquo;s world.</p><p>The Wiki is pretty useful when you are trying to find out on the run whether that Chinchilla Man you just saw is hostile or not. But what if you don&rsquo;t want to open a browser every time you want to find it out? Or if you want to use that information locally for something?</p><p>With the game nowadays having up to 700 different creatures, you surely won&rsquo;t mannualy gather that information for yourself.</p><h2 id=web-scraping-and-web-crawling>Web Scraping and Web Crawling<a hidden class=anchor aria-hidden=true href=#web-scraping-and-web-crawling>#</a></h2><p>Well you can create a program to extract the data you want from the website in an automated fashion. We call this <strong>Web Scraping</strong>. Now, Web Scraping often goes hand in hand with <strong>Web Crawling</strong>, and that&rsquo;s when you, from a base page, start to follow links and also visit other pages. Web crawlers are also widely reffered to as bots or spiders.</p><h3 id=scraping-creatures>Scraping Creatures<a hidden class=anchor aria-hidden=true href=#scraping-creatures>#</a></h3><p>If you head to the <a href=https://dwarffortresswiki.org/index.php/DF2014:Creature>Creature</a> page of the Dwarf Fortress Wiki, you&rsquo;ll see tables containing informations about each creature of the game. There&rsquo;s a name and hostile fields. That&rsquo;s the information we are looking for.</p><figure><img loading=lazy src=/img/dwarf_fortress_table.png width=1000 height=1000></figure><h3 id=scrapy>Scrapy<a hidden class=anchor aria-hidden=true href=#scrapy>#</a></h3><p>Scrapy is an open source framework for Web Scraping and Web Crawling in Python<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>. Using Scrapy makes it easy to request and parse HTML, as it handles a lot of it for us. It&rsquo;s simple to set it up and get it running. Let&rsquo;s dive right in to it!</p><p>To install it, simply open a terminal and</p><pre><code>pip install scrapy
</code></pre><p>The first thing to do when working with Scrapy is to set up the framework for our spiders, which can be done through the command <code>scrapy startproject</code> followed by the project name. I will call my project &lsquo;dwarf_fortress&rsquo; so,</p><pre><code>scrapy startproject dwarf_fortress
</code></pre><p>Scrapy will <strong>create generic folders, code and config for our crawlers</strong>. The structure will be something like:</p><pre><code>
────dwarf_fortress
    │   scrapy.cfg
    │
    └───dwarf_fortress
        │   items.py
        │   middlewares.py
        │   pipelines.py
        │   settings.py
        │   __init__.py
        │
        ├───spiders
        │   │   __init__.py
        │   │
        │   └───__pycache__
        └───__pycache__

</code></pre><p>Now that we&rsquo;ve created a project, let&rsquo;s go into the directory &lsquo;dwarf_fortress&rsquo; and run another command to make Scrapy set up a generic spider for us. That&rsquo;s a good starting point.</p><p>I&rsquo;ll name it &lsquo;Creatures&rsquo; and say that the base url is <a href=https://dwarffortresswiki.org/index.php/DF2014:Creature>&lsquo;dwarffortresswiki.org/index.php/DF2014:Creature&rsquo;</a>.</p><pre><code>cd dwarf_fortress
scrapy genspider Creatures dwarffortresswiki.org/index.php/DF2014:Creature

</code></pre><p>You should be able to see the created spider as a new file in the &lsquo;spiders&rsquo; folder called <code>Creatures.py</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Creatures.py</span>
<span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> scrapy


<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CreaturesSpider</span>(scrapy<span style=color:#f92672>.</span>Spider):
    name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;Creatures&#39;</span>
    allowed_domains <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;dwarffortresswiki.org/index.php/DF2014:Creature&#39;</span>]
    start_urls <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;http://dwarffortresswiki.org/index.php/DF2014:Creature/&#39;</span>]

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parse</span>(self, response):
        <span style=color:#66d9ef>pass</span>


</code></pre></div><p>The class CreaturesSpider represents the spider that will grab each creature name hostile information from the Wiki. <code>AllowedDomains</code> restrict the domain of sites the spider can visit.</p><p>Notice that the start url has &lsquo;http&rsquo; protocol, while the Wiki uses &lsquo;https&rsquo;. That alone will make our spider crash, so be sure to fix it.</p><p>Our spider will request the <code>start_url</code> and pass the HTTP response to the <code>parse</code> method. And that&rsquo;s where we&rsquo;ll code to fetch the data we need.</p><p>But first we need to define the structure of the information we are collecting. We can do it in the <code>items.py</code> file. There, we define Classes that represent the information as &lsquo;scrapy.Items&rsquo; which are the containers for the data scrapped. Let&rsquo;s add a <code>name</code> and <code>hostile</code> field.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>
<span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#75715e># Define here the models for your scraped items</span>
<span style=color:#f92672>import</span> scrapy

<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DwarfFortressItem</span>(scrapy<span style=color:#f92672>.</span>Item):
    <span style=color:#75715e># define the fields for your item here like:</span>
    <span style=color:#75715e># name = scrapy.Field()</span>

    name <span style=color:#f92672>=</span> scrapy<span style=color:#f92672>.</span>Field()
    hostile <span style=color:#f92672>=</span> scrapy<span style=color:#f92672>.</span>Field()

</code></pre></div><p>Now, the last thing we need to do before running the crawler, is to tell our spider <strong>where</strong> are the name and hostile fields in the HTTP response.</p><h3 id=xpath>Xpath<a hidden class=anchor aria-hidden=true href=#xpath>#</a></h3><p>We can use Xpath syntax in Scrapy to grab only the elements we need from the page.</p><p>By opening the Wiki <a href=https://dwarffortresswiki.org/index.php/DF2014:Creature>&lsquo;Creature page&rsquo;</a> in a web browser, we can right click one creature&rsquo;s Hostile field and go to Inspect Element.</p><p><figure><img loading=lazy src=/img/dwarf_fortress_creature_xpath_table.png width=500 height=500></figure><figure><img loading=lazy src=/img/dwarf_fortress_creature_xpath.png width=500 height=500></figure></p><p>Now, we have to write the path to each field. We start from the outside to the inside, so we first grab every row of every table that has a class &lsquo;wikitable sortable jquery-tablesorter&rsquo;. In Xpath,</p><p>row -> <code>//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr</code></p><p>Now, for every row, we take the text of the second element (notice that the text for the &lsquo;name&rsquo; element is located at &lsquo;td/a&rsquo;) and the text of the fourth element.</p><p>name (inside row)-> <code>./td[2]/a/text()</code></p><p>hostile (inside row) -> <code>./td[4]/text()</code></p><h3 id=putting-it-all-together>Putting it all together<a hidden class=anchor aria-hidden=true href=#putting-it-all-together>#</a></h3><p>Heading back to the parse method, we import our DwarfFortressItem and write the logic to fetch name and hostile from the response.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>
<span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> scrapy
<span style=color:#f92672>from</span> dwarf_fortress.items <span style=color:#f92672>import</span> DwarfFortressItem

<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CreaturesSpider</span>(scrapy<span style=color:#f92672>.</span>Spider):
    name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;Creatures&#39;</span>
    allowed_domains <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;dwarffortresswiki.org/index.php&#39;</span>]
    start_urls <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;https://dwarffortresswiki.org/index.php/DF2014:Creature&#39;</span>]

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parse</span>(self, response):

        table_rows <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>xpath(<span style=color:#e6db74>&#34;//table[@class=&#39;wikitable sortable jquery-tablesorter&#39;]/tbody/tr&#34;</span>)
        
        <span style=color:#66d9ef>for</span> row <span style=color:#f92672>in</span> table_rows:
            name <span style=color:#f92672>=</span> row<span style=color:#f92672>.</span>xpath(<span style=color:#e6db74>&#34;./td[2]/a/text()&#34;</span>)<span style=color:#f92672>.</span>get()
            hostile <span style=color:#f92672>=</span> row<span style=color:#f92672>.</span>xpath(<span style=color:#e6db74>&#34;./td[4]/text()&#34;</span>)<span style=color:#f92672>.</span>get()

            <span style=color:#66d9ef>if</span> name <span style=color:#f92672>and</span> hostile:
                creature <span style=color:#f92672>=</span> DwarfFortressItem(name<span style=color:#f92672>=</span>name, hostile<span style=color:#f92672>=</span>hostile<span style=color:#f92672>.</span>strip(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>))
                <span style=color:#66d9ef>yield</span> creature

</code></pre></div><p>If name and hostile are not null (that avoids returning other page elements that may happen to match the Xpath), we yield our DwarfFortressItem defined previously.</p><p>To run our crawler and save the output to a json file,</p><p><code>scrapy crawl Creatures -o output.json</code></p><p>And that&rsquo;s it! Looking at the output&rsquo;s first elements, we&rsquo;ve successfully scraped the Dwarf Fortress Wiki for Creature name and Hostile information!</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>[
{<span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Dwarf&#34;</span>, <span style=color:#f92672>&#34;hostile&#34;</span>: <span style=color:#e6db74>&#34;No&#34;</span>},
{<span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Elf&#34;</span>, <span style=color:#f92672>&#34;hostile&#34;</span>: <span style=color:#e6db74>&#34;Variable&#34;</span>},
{<span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Goblin&#34;</span>, <span style=color:#f92672>&#34;hostile&#34;</span>: <span style=color:#e6db74>&#34;Usually&#34;</span>},
{<span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Human&#34;</span>, <span style=color:#f92672>&#34;hostile&#34;</span>: <span style=color:#e6db74>&#34;Variable&#34;</span>},
{<span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Kobold&#34;</span>, <span style=color:#f92672>&#34;hostile&#34;</span>: <span style=color:#e6db74>&#34;Usually&#34;</span>},
{<span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Amphibian man&#34;</span>, <span style=color:#f92672>&#34;hostile&#34;</span>: <span style=color:#e6db74>&#34;Variable&#34;</span>},
{<span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Antman&#34;</span>, <span style=color:#f92672>&#34;hostile&#34;</span>: <span style=color:#e6db74>&#34;Variable&#34;</span>},


</code></pre></div><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p><a href=http://www.bay12games.com/dwarves/>http://www.bay12games.com/dwarves/</a> <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p><a href=https://dwarffortresswiki.org/>https://dwarffortresswiki.org/</a> <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p><a href=https://scrapy.org/>https://scrapy.org/</a> <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://maugomes.netlify.app/tags/python/>Python</a></li><li><a href=https://maugomes.netlify.app/tags/web-scraping/>Web Scraping</a></li><li><a href=https://maugomes.netlify.app/tags/web-crawling/>Web Crawling</a></li><li><a href=https://maugomes.netlify.app/tags/dwarf-fortress/>Dwarf Fortress</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://maugomes.netlify.app/>Mauício's Log Book</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button>
</a><img src=/img/catruns.gif width=50% style=display:block;margin-left:auto;margin-right:auto>
<script defer src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>